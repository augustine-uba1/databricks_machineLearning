{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "c9HU1STRUknn"
      ],
      "authorship_tag": "ABX9TyNGbUW2RbFoTtDrzpkwoeXv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/augustine-uba1/databricks_machineLearning/blob/main/PySPark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PySpark Introduction"
      ],
      "metadata": {
        "id": "c9HU1STRUknn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FnVfIyPMH9Vm",
        "outputId": "2153fa8f-7f19-418a-a90c-4b4f4b165860"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.4.1.tar.gz (310.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.4.1-py2.py3-none-any.whl size=311285398 sha256=ed3d3a12b72723e70e1ecad6d7143e93fd77391e9c296f747dfa43883afbd9a8\n",
            "  Stored in directory: /root/.cache/pip/wheels/0d/77/a3/ff2f74cc9ab41f8f594dabf0579c2a7c6de920d584206e0834\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.4.1\n"
          ]
        }
      ],
      "source": [
        "## Install pyspark\n",
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import pyspark**"
      ],
      "metadata": {
        "id": "Hbh4AI22O4X4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark"
      ],
      "metadata": {
        "id": "Codqi1XkI_Eq"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## import the SparkSession class from the pyspark.sql module. The SparkSession class is the entry point for working with Spark SQL in PySpark\n",
        "##create a SparkSession object named spark, In the below example, the appName parameter is set to 'Sample'\n",
        "##getOrCreate method checks if a SparkSession already exists. If it does, it returns the existing SparkSession; otherwise, it creates a new one\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName('Sample').getOrCreate()"
      ],
      "metadata": {
        "id": "wvnIHAirL9dw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "UJinXIh2MBzY",
        "outputId": "fb184a9d-030e-4397-c0b5-1d706b4bdd31"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7c1ec18364d0>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://5f45522b6118:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.4.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Sample</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## read a csv file into a pyspark dataframe. You can specify the read format, csv, parquet, table.. see documentation for more read formats\n",
        "pyspark_df = spark.read.option('header', 'true').csv('users1.csv')"
      ],
      "metadata": {
        "id": "9cfnL1nLMCZD"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pyspark_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFLdv0uxSdbm",
        "outputId": "69fd3904-3216-4fca-cbde-3ad8a1d1ae8f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+----+----------+------+\n",
            "|Username| Age|experience|income|\n",
            "+--------+----+----------+------+\n",
            "|     Sam|  54|        15| 50000|\n",
            "|  Justin|  31|        12| 35000|\n",
            "|    Phil|  20|         5| 25000|\n",
            "|  Roland|  25|         7| 40000|\n",
            "|   Lucas|null|      null| 50000|\n",
            "|    null|  56|         5|  null|\n",
            "|    null|  32|      null|  null|\n",
            "+--------+----+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(pyspark_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9R65qNn6SlRM",
        "outputId": "d874a32a-47dd-4613-df08-b993845ad22c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.sql.dataframe.DataFrame"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pyspark_df.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WyEhqzAaUpG1",
        "outputId": "280a3e0f-0338-4dd6-cbe3-4be0bbcbbdd0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Username', 'string'),\n",
              " ('Age', 'string'),\n",
              " ('experience', 'string'),\n",
              " ('income', 'string')]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pyspark_df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6uoAACCUBoN",
        "outputId": "1168d49b-9116-420b-8b39-6973da32dc7d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Username: string (nullable = true)\n",
            " |-- Age: string (nullable = true)\n",
            " |-- experience: string (nullable = true)\n",
            " |-- income: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pyspark_df.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1qY4__XTt40",
        "outputId": "b839df8b-cf5b-4eb7-dd89-eae629f493a0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(Username='Sam', Age='54', experience='15', income='50000'),\n",
              " Row(Username='Justin', Age='31', experience='12', income='35000'),\n",
              " Row(Username='Phil', Age='20', experience='5', income='25000'),\n",
              " Row(Username='Roland', Age='25', experience='7', income='40000'),\n",
              " Row(Username='Lucas', Age=None, experience=None, income='50000')]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Wrangling - Dataframe operations\n",
        "*   viewing datatype schema\n",
        "*   returning specific columns and column indexing\n",
        "*   adding, dropping and renaming columns\n",
        "\n"
      ],
      "metadata": {
        "id": "sxhZKya8VhcL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## check datatype schema\n",
        "pyspark_df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GmAzDPteVo80",
        "outputId": "0699002c-9d96-492e-ffeb-ea5e28bbf209"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Username: string (nullable = true)\n",
            " |-- Age: integer (nullable = true)\n",
            " |-- experience: integer (nullable = true)\n",
            " |-- income: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## here we specify the data types of the columns\n",
        "pyspark_df = spark.read.csv('users1.csv', header=True, inferSchema = True)\n",
        "pyspark_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yh6izIggcIzw",
        "outputId": "73ab06f9-3579-41d4-98d4-6391aa7c6524"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+----+----------+------+\n",
            "|Username| Age|experience|income|\n",
            "+--------+----+----------+------+\n",
            "|     Sam|  54|        15| 50000|\n",
            "|  Justin|  31|        12| 35000|\n",
            "|    Phil|  20|         5| 25000|\n",
            "|  Roland|  25|         7| 40000|\n",
            "|   Lucas|null|      null| 50000|\n",
            "|    null|  56|         5|  null|\n",
            "|    null|  32|      null|  null|\n",
            "+--------+----+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## check datatype schema\n",
        "pyspark_df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18wQ3kSUcTBv",
        "outputId": "3d71fd1c-84e0-4593-d2f3-fdadc0066da3"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Username: string (nullable = true)\n",
            " |-- Age: integer (nullable = true)\n",
            " |-- experience: integer (nullable = true)\n",
            " |-- income: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## selecting multiple columns\n",
        "pyspark_df.select(['Username', 'experience']).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejrF6B8ucWFj",
        "outputId": "616d94d9-d34e-4593-efd9-7809cfec47bc"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+----------+\n",
            "|Username|experience|\n",
            "+--------+----------+\n",
            "|     Sam|        15|\n",
            "|  Justin|        12|\n",
            "|    Phil|         5|\n",
            "|  Roland|         7|\n",
            "|   Lucas|      null|\n",
            "|    null|         5|\n",
            "|    null|      null|\n",
            "+--------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##indexing a column\n",
        "indexed_col = pyspark_df.select(pyspark_df[ 'experience',][0].alias(\"indexed_col\"))\n",
        "indexed_col.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAPLw7yxiTYp",
        "outputId": "f33440fe-b0ac-4e81-8330-32750cecf12e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+\n",
            "|indexed_col|\n",
            "+-----------+\n",
            "|         15|\n",
            "|         12|\n",
            "|          5|\n",
            "|          7|\n",
            "|       null|\n",
            "|          5|\n",
            "|       null|\n",
            "+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## describing (summarysing) values in a dataframe\n",
        "pyspark_df.describe().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_w0rds5asUBs",
        "outputId": "ff8695e2-7fee-4365-c81b-8b5687563a23"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------+------------------+-----------------+------------------+\n",
            "|summary|Username|               Age|       experience|            income|\n",
            "+-------+--------+------------------+-----------------+------------------+\n",
            "|  count|       5|                 6|                5|                 5|\n",
            "|   mean|    null|36.333333333333336|              8.8|           40000.0|\n",
            "| stddev|    null|15.108496505829647|4.494441010848846|10606.601717798214|\n",
            "|    min|  Justin|                20|                5|             25000|\n",
            "|    max|     Sam|                56|               15|             50000|\n",
            "+-------+--------+------------------+-----------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## adding columns in dataframes\n",
        "pyspark_df_add = pyspark_df.withColumn('experience after 10 years', pyspark_df['experience'] + 10)\n",
        "pyspark_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IH4nPybauhRI",
        "outputId": "1c01b39e-94bf-408e-d9e8-2d83fa18848e"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+----+----------+------+\n",
            "|Username| Age|experience|income|\n",
            "+--------+----+----------+------+\n",
            "|     Sam|  54|        15| 50000|\n",
            "|  Justin|  31|        12| 35000|\n",
            "|    Phil|  20|         5| 25000|\n",
            "|  Roland|  25|         7| 40000|\n",
            "|   Lucas|null|      null| 50000|\n",
            "|    null|  56|         5|  null|\n",
            "|    null|  32|      null|  null|\n",
            "+--------+----+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## droping a column\n",
        "pyspark_df_drop = pyspark_df.drop('experience after 10 years')\n",
        "pyspark_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8hVVTXDvU1G",
        "outputId": "15097e8f-3e08-4109-9d1e-ce1d3c51170f"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+----+----------+------+\n",
            "|Username| Age|experience|income|\n",
            "+--------+----+----------+------+\n",
            "|     Sam|  54|        15| 50000|\n",
            "|  Justin|  31|        12| 35000|\n",
            "|    Phil|  20|         5| 25000|\n",
            "|  Roland|  25|         7| 40000|\n",
            "|   Lucas|null|      null| 50000|\n",
            "|    null|  56|         5|  null|\n",
            "|    null|  32|      null|  null|\n",
            "+--------+----+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Rename a column\n",
        "pyspark_df.withColumnRenamed('experience', 'working years').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UziYngyWvmT8",
        "outputId": "3e77eaa9-9320-4d40-b2d4-f1daeac770f9"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+----+-------------+------+\n",
            "|Username| Age|working years|income|\n",
            "+--------+----+-------------+------+\n",
            "|     Sam|  54|           15| 50000|\n",
            "|  Justin|  31|           12| 35000|\n",
            "|    Phil|  20|            5| 25000|\n",
            "|  Roland|  25|            7| 40000|\n",
            "|   Lucas|null|         null| 50000|\n",
            "|    null|  56|            5|  null|\n",
            "|    null|  32|         null|  null|\n",
            "+--------+----+-------------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Wrangling2 - Dataframe Opertaions\n",
        "\n",
        "\n",
        "*   Droping columns, Droping rows, parameters in dropping functionalities\n",
        "*   Handling missing values using mean, median, mode\n",
        "\n"
      ],
      "metadata": {
        "id": "_HgfCjSs8KGV"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "62uxEEnR8nkZ"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Wrangling 2 - Dataframes operations\n",
        "\n",
        "\n",
        "*   Drop columns, drop rows, parameters in dropping functionalities\n",
        "*   Handling missing values by mean, median and mode\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_9wZfGxr8vEA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pyspark_df.describe().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OOelRqMo9CHD",
        "outputId": "284274ec-3099-4a2a-afdd-19e7aef66426"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------+------------------+-----------------+------------------+\n",
            "|summary|Username|               Age|       experience|            income|\n",
            "+-------+--------+------------------+-----------------+------------------+\n",
            "|  count|       5|                 6|                5|                 5|\n",
            "|   mean|    null|36.333333333333336|              8.8|           40000.0|\n",
            "| stddev|    null|15.108496505829647|4.494441010848846|10606.601717798214|\n",
            "|    min|  Justin|                20|               12|             25000|\n",
            "|    max|     Sam|                56|                7|             50000|\n",
            "+-------+--------+------------------+-----------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## droping rows with null values (by default 'any' is set as all if no values are specified)\n",
        "\n",
        "pyspark_df.na.drop(how=\"any\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vsh1DXj-zfi",
        "outputId": "1b88605e-b404-4b65-fa45-ccd426200dce"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+---+----------+------+\n",
            "|Username|Age|experience|income|\n",
            "+--------+---+----------+------+\n",
            "|     Sam| 54|        15| 50000|\n",
            "|  Justin| 31|        12| 35000|\n",
            "|    Phil| 20|         5| 25000|\n",
            "|  Roland| 25|         7| 40000|\n",
            "+--------+---+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## droping rows with null values using all (drops only rows where all values are null)\n",
        "pyspark_df.na.drop(how=\"all\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSm-uquLA9L0",
        "outputId": "765abc53-78dc-4113-bb55-749e5a40a15b"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+----+----------+------+\n",
            "|Username| Age|experience|income|\n",
            "+--------+----+----------+------+\n",
            "|     Sam|  54|        15| 50000|\n",
            "|  Justin|  31|        12| 35000|\n",
            "|    Phil|  20|         5| 25000|\n",
            "|  Roland|  25|         7| 40000|\n",
            "|   Lucas|null|      null| 50000|\n",
            "|    null|  56|         5|  null|\n",
            "|    null|  32|      null|  null|\n",
            "+--------+----+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## droping rows with null values (thresh=2 ommits rows where there are at least two values in the entire column)\n",
        "pyspark_df.na.drop(how=\"any\", thresh=2).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bT9I5O8aBCgp",
        "outputId": "811cebae-d30d-44a9-8578-6f3b9c3ad65f"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+----+----------+------+\n",
            "|Username| Age|experience|income|\n",
            "+--------+----+----------+------+\n",
            "|     Sam|  54|        15| 50000|\n",
            "|  Justin|  31|        12| 35000|\n",
            "|    Phil|  20|         5| 25000|\n",
            "|  Roland|  25|         7| 40000|\n",
            "|   Lucas|null|      null| 50000|\n",
            "|    null|  56|         5|  null|\n",
            "+--------+----+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## using subset - removes only null values in specified rows\n",
        "pyspark_df.na.drop(subset=['experience']).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7YYZdlHYB01a",
        "outputId": "adc25190-ba2d-4f98-cd8b-485944d98856"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+---+----------+------+\n",
            "|Username|Age|experience|income|\n",
            "+--------+---+----------+------+\n",
            "|     Sam| 54|        15| 50000|\n",
            "|  Justin| 31|        12| 35000|\n",
            "|    Phil| 20|         5| 25000|\n",
            "|  Roland| 25|         7| 40000|\n",
            "|    null| 56|         5|  null|\n",
            "+--------+---+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## replacing all missing values, if columns are not specified, missing values in all columns are replaced\n",
        "pyspark_df.na.fill('missing value', ['age', 'experience']).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzDksEiBCRlr",
        "outputId": "b6da86fd-2368-4054-8363-418abfc07fcd"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-------------+-------------+------+\n",
            "|Username|          Age|   experience|income|\n",
            "+--------+-------------+-------------+------+\n",
            "|     Sam|           54|           15| 50000|\n",
            "|  Justin|           31|           12| 35000|\n",
            "|    Phil|           20|            5| 25000|\n",
            "|  Roland|           25|            7| 40000|\n",
            "|   Lucas|missing value|missing value| 50000|\n",
            "|    null|           56|            5|  null|\n",
            "|    null|           32|missing value|  null|\n",
            "+--------+-------------+-------------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## replacing all missing values with row operations, here we make use of the inputer function imported from pyspark, and the format() Python method\n",
        "from pyspark.ml.feature import Imputer\n",
        "\n",
        "imputer = Imputer(\n",
        "                  inputCols=['Age', 'experience', 'income'],\n",
        "                  outputCols=[\"{}_input_value\".format(c) for c in ['Age', 'experience', 'income']]\n",
        "                ).setStrategy(\"mean\")"
      ],
      "metadata": {
        "id": "oQ4fmRZ5C97Q"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## add the new columns to the dataframe and displays the new dataframe\n",
        "new_imput =imputer.fit(pyspark_df).transform(pyspark_df)\n",
        "new_imput.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffJDgVZRHmGG",
        "outputId": "605bca1e-39dc-4b4d-a17a-e3899ebde89f"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+----+----------+------+---------------+----------------------+------------------+\n",
            "|Username| Age|experience|income|Age_input_value|experience_input_value|income_input_value|\n",
            "+--------+----+----------+------+---------------+----------------------+------------------+\n",
            "|     Sam|  54|        15| 50000|             54|                    15|             50000|\n",
            "|  Justin|  31|        12| 35000|             31|                    12|             35000|\n",
            "|    Phil|  20|         5| 25000|             20|                     5|             25000|\n",
            "|  Roland|  25|         7| 40000|             25|                     7|             40000|\n",
            "|   Lucas|null|      null| 50000|             36|                     8|             50000|\n",
            "|    null|  56|         5|  null|             56|                     5|             40000|\n",
            "|    null|  32|      null|  null|             32|                     8|             40000|\n",
            "+--------+----+----------+------+---------------+----------------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_pyspark_df = new_imput.drop('Age', 'experience', 'income')\n",
        "new_pyspark_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wy1MN-k4HoYt",
        "outputId": "3a4a104c-095f-44c0-c797-4f80107f3201"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+---------------+----------------------+------------------+\n",
            "|Username|Age_input_value|experience_input_value|income_input_value|\n",
            "+--------+---------------+----------------------+------------------+\n",
            "|     Sam|             54|                    15|             50000|\n",
            "|  Justin|             31|                    12|             35000|\n",
            "|    Phil|             20|                     5|             25000|\n",
            "|  Roland|             25|                     7|             40000|\n",
            "|   Lucas|             36|                     8|             50000|\n",
            "|    null|             56|                     5|             40000|\n",
            "|    null|             32|                     8|             40000|\n",
            "+--------+---------------+----------------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## filter operations - without uing the select method all columns in the dataframe are returned\n",
        "new_pyspark_df.filter(\"income_input_value >= 35000\" ).select(['Username', 'income_input_Value']).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXSZv9ogJi6B",
        "outputId": "68f6d4a5-83f0-4f0a-8092-a30410e5ff87"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+------------------+\n",
            "|Username|income_input_Value|\n",
            "+--------+------------------+\n",
            "|     Sam|             50000|\n",
            "|  Justin|             35000|\n",
            "|  Roland|             40000|\n",
            "|   Lucas|             50000|\n",
            "|    null|             40000|\n",
            "|    null|             40000|\n",
            "+--------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## using &, |\n",
        "new_pyspark_df.filter((new_pyspark_df['income_input_Value'] > 35000)  |\n",
        "                       (new_pyspark_df['Age_input_value'] > 30) ).select(['Username', 'income_input_Value']).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1IVen1GELEe0",
        "outputId": "55821a70-b806-46b6-abbe-d727754116f8"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+------------------+\n",
            "|Username|income_input_Value|\n",
            "+--------+------------------+\n",
            "|     Sam|             50000|\n",
            "|  Justin|             35000|\n",
            "|  Roland|             40000|\n",
            "|   Lucas|             50000|\n",
            "|    null|             40000|\n",
            "|    null|             40000|\n",
            "+--------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## using  ~\n",
        "new_pyspark_df.filter(~(new_pyspark_df['income_input_Value'] > 35000)).select(['Username', 'income_input_Value']).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4fYuhrMMNSE",
        "outputId": "98af36bf-29e4-4575-b35a-a10de294af06"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+------------------+\n",
            "|Username|income_input_Value|\n",
            "+--------+------------------+\n",
            "|  Justin|             35000|\n",
            "|    Phil|             25000|\n",
            "+--------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Grouping and aggregation of dataframes"
      ],
      "metadata": {
        "id": "xsb7cW3iN1DZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "department_df = spark.read.csv('departments.csv', header=True, inferSchema = True)\n",
        "department_df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tsh1j0IlN5eN",
        "outputId": "5755e79e-ff1a-487f-df17-72ebf3362cc1"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Username: string (nullable = true)\n",
            " |-- Department: string (nullable = true)\n",
            " |-- Salary: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## group by name and the sum aggregate\n",
        "department_df.groupBy('Username').sum().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txOHqIhWP_Xz",
        "outputId": "ce366f36-3ca4-4cee-a6c3-2a5e32521ac6"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-----------+\n",
            "|Username|sum(Salary)|\n",
            "+--------+-----------+\n",
            "|    Kate|      75000|\n",
            "|    Jack|      41000|\n",
            "|   Lewis|      96000|\n",
            "|    John|      71000|\n",
            "|     Sam|      36000|\n",
            "|  Olivia|      60000|\n",
            "+--------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## group by column (department) and the mean aggregate\n",
        "department_df.groupBy('department').mean().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwnmHQXqQ0Vp",
        "outputId": "94e82bd9-e92e-4fe4-99d3-c525fdd8668b"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+------------------+\n",
            "|      department|       avg(Salary)|\n",
            "+----------------+------------------+\n",
            "|             IOT|32333.333333333332|\n",
            "|        big data|           42000.0|\n",
            "|machine learning|           37500.0|\n",
            "|data engineering|           40500.0|\n",
            "+----------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## group by column (department) and the count aggregate\n",
        "department_df.groupBy('department').count().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHsYZEQqRJHT",
        "outputId": "88fdfa5a-04e0-4d08-c8c5-ad700a05a714"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+-----+\n",
            "|      department|count|\n",
            "+----------------+-----+\n",
            "|             IOT|    3|\n",
            "|        big data|    3|\n",
            "|machine learning|    2|\n",
            "|data engineering|    2|\n",
            "+----------------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## agg function - Aggregate on the entire DataFrame without group\n",
        "department_df.agg({\"Salary\": \"max\"}).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TILLkx2WSHLg",
        "outputId": "90bf3b5a-87f2-4e92-dc52-8bca7d6b8331"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+\n",
            "|max(Salary)|\n",
            "+-----------+\n",
            "|      56000|\n",
            "+-----------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}